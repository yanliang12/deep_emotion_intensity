{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daeb0ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0a7b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:57:09.801121: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-03 12:57:09.801161: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from deep_emotion_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4baeb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emoint_data_conversion import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d33872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/03 12:57:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "sc = SparkContext(\"local\")\n",
    "sqlContext = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eaeeae",
   "metadata": {},
   "source": [
    "# prepare the data for tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5bd0d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py:138: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\n",
      "/emotion_intensity/deep_emotion_model.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = numpy.array(word_id_sequence)\n"
     ]
    }
   ],
   "source": [
    "fear_texts, fear_tags = convert_file_to_text_and_tag_list(\n",
    "    emotion_tag = \"fear\",\n",
    "    data_file = \"/data/emoint/*.train.txt\",\n",
    "    sqlContext = sqlContext)\n",
    "fear_texts = texts_to_input(fear_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5b824b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 12:57:18.378548: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-03 12:57:18.378607: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-03 12:57:18.378624: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (07b0cb0e5eeb): /proc/driver/nvidia/version does not exist\n",
      "2022-04-03 12:57:18.380737: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv1d\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/Conv1D/ExpandDims, conv1d/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,300], [1,2,300,128].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1, 300), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fear_tagger \u001b[38;5;241m=\u001b[39m \u001b[43memotion_tagger_model_building\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/emotion_intensity/deep_emotion_model.py:47\u001b[0m, in \u001b[0;36memotion_tagger_model_building\u001b[0;34m(sequence_length, max_features, embedding_dim, filters, kernel_size, dropout_rate)\u001b[0m\n\u001b[1;32m     45\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDropout(dropout_rate)(x)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Conv1D + global max pooling\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv1D(filters, kernel_size, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n\u001b[1;32m     49\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mGlobalMaxPooling1D()(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py:2013\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   2010\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[1;32m   2011\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2012\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m-> 2013\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[1;32m   2015\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c_op\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"conv1d\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/Conv1D/ExpandDims, conv1d/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,300], [1,2,300,128].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1, 300), dtype=float32)"
     ]
    }
   ],
   "source": [
    "fear_tagger = emotion_tagger_model_building()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "fear_tagger.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeab45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fear_texts[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fear_tagger.fit(\n",
    "    fear_texts[0:2],\n",
    "    fear_tags[0:2]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3496528",
   "metadata": {},
   "outputs": [],
   "source": [
    "fear_texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
